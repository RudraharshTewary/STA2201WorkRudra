---
title: "Applied_Stat_2_Lab_2"
format: pdf
editor: visual
---

## Quarto

```{r}
#| message: false
library(opendatatoronto)
library(tidyverse)
library(stringr)
library(skimr) # EDA
library(visdat) # EDA
library(janitor)
library(lubridate)
library(ggrepel)
```

```{r}
all_data <- list_packages(limit = 500)
head(all_data)
```


```{r}
res <- list_package_resources("996cfe8d-fb35-40ce-b569-698d51fc683b") # obtained code from searching data frame above
res <- res |> mutate(year = str_extract(name, "202.?"))
delay_2022_ids <- res |> filter(year==2022) |> select(id) |> pull()

delay_2022 <- get_resource(delay_2022_ids)

# make the column names nicer to work with
delay_2022 <- clean_names(delay_2022)
```

```{r}

# note: I obtained these codes from the 'id' column in the `res` object above
delay_codes <- get_resource("3900e649-f31e-4b79-9f20-4731bbfd94f7")
delay_data_codebook <- get_resource("ca43ac3d-3940-4315-889b-a9375e7b8aa4")
```

```{r}
head(delay_2022)
```

## Answer 1)

We can do this task through the following code
```{r}
delay_2022 |>
  group_by(station,line) |>
  summarise(mean_delay=mean(min_delay)) |>
  arrange(-mean_delay)|>
  head(5) |>
  ggplot(aes(x = station,
             y = mean_delay))+
  geom_col()+
  facet_wrap(.~line)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


## Answer 2)

We will do this by first filtering the codes responsible for 50% of the delays, and then extract them, filter the table on the basis of the codes obtained and finally model the delay.

```{r}
delay_2022 <- delay_2022 |> 
  left_join(delay_codes |> rename(code = `SUB RMENU CODE`, code_desc = `CODE DESCRIPTION...3`) |> select(code, code_desc)) 

delay_2022_top_0.5 <- delay_2022 |>
                      filter(min_delay>0)|>
                      group_by(code)|>
                      summarise(no_rows = length(code))|>
                      arrange(-no_rows)|>
                      mutate(cumulative_sum = cumsum(no_rows))|>
                      mutate(half_sum = sum(no_rows)/2)|>
                      filter(cumulative_sum<=half_sum)
delay_2022_top_0.5
frequent_delay_codes <- delay_2022_top_0.5$code
frequent_delay_codes

lm_table_delay_code <- delay_2022|>
                      filter(min_delay>0 & (code %in% frequent_delay_codes))

delay_model <- lm(min_delay ~ line + code, data = lm_table_delay_code)
summary(delay_model)
lm_table_delay_code

            
```
It would first seem that our results for the most frequent causes of delays dont seem to agree with our EDA results, where in Delays were caused due to major incidents like accidents, maintenance, power/track failures, fires, bomb threats and so on. However, that is because the parameter for interest in that scenario was mean_delay, which gets skewed by these delay reasons as they cause the highest amount of delay, hence skewing the mean. In terms of the factors which most frequently cause delays, our obtained delay codes make sense, and in a way also agree with the data. Though, it has to be said that in this case, a linear model with an interaction term was not able to get a good fit over the data, with an $R^2$ of only 0.17.

## Answer 3)
We proceed to get the data and perform pre-processing in the following code block

```{r}
library(opendatatoronto)
library(janitor)
all_data <- search_packages("campaign")
campaign_id <- all_data$id
resource <- list_package_resources(campaign_id[1])
resource
campaign_data <- get_resource('8b42906f-c894-4e93-a98e-acac200f34a4')
campaign_data_mayoral <- campaign_data[[2]]
colnames(campaign_data_mayoral) <- as.character(campaign_data_mayoral[1,])
campaign_data_mayoral <- campaign_data_mayoral[-1,]
rownames(campaign_data_mayoral) <- NULL
campaign_data_mayoral <- clean_names(campaign_data_mayoral)
campaign_data_mayoral



```

## Answer 4)

We have multiple variables in the dataset, detailing the information of both donors and the candidates they donated to. However, there is an issue where in many columns/Data fields are outright blank or have missing values, so upon exploration we see that columns like 'contributors_address','authorized_representative','president_business_manager','relationship_to_candidate' are mostly blank, presumably due to lack of information or privacy concerns. While, columns like 'goods_or_services_desc' are mostly blank due to very few donations in the name of goods or services. At the same time, 'contribution_amount' is recorded as a character data type while 'Contribution_type_desc' should be recorded as a factor. So in the next code block we implement all these changes

```{r}
not_all_na <- function(x) all(!is.na(x))
campaign_data_mayoral <- campaign_data_mayoral|>
                          select(where(not_all_na))
campaign_data_mayoral
campaign_data_mayoral$contributor_type_desc <- as.factor(campaign_data_mayoral$contributor_type_desc)
campaign_data_mayoral$contribution_type_desc <- as.factor(campaign_data_mayoral$contribution_type_desc)
campaign_data_mayoral$contribution_amount <- as.numeric(campaign_data_mayoral$contribution_amount)
campaign_data_mayoral
                         



```

## Answer 5)

We use the following plots to see the distribution of contributions in the data

```{r}
campaign_data_mayoral |> arrange(-contribution_amount)

ggplot(data = campaign_data_mayoral,aes(x=contribution_amount))+
  geom_dotplot()

campaign_data_mayoral_contribution_distribution <- 
  campaign_data_mayoral |> filter(contribution_amount < 500000)

ggplot(data=campaign_data_mayoral_contribution_distribution, aes(x=contribution_amount))+
  geom_dotplot()

campaign_data_mayoral_contribution_distribution_2 <- 
  campaign_data_mayoral |> filter(contribution_amount < 10000)

ggplot(data=campaign_data_mayoral_contribution_distribution_2, aes(x=contribution_amount))+
  geom_histogram()



ggplot(data = campaign_data_mayoral, aes(x = candidate,
                                         y = contribution_amount,
                                         color = contribution_type_desc ))+
  geom_point()+
  geom_smooth()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```
In the multiple plots we obtained above we see the following. A main outlier is the self donation of \$500,000 done by Doug Ford for himself there are also a few other big donations close to \$100,000 done by candidates Ryan Emond and Rob Ford to themselves, these outliers are skewing the graphs of contribution amounts. Accounting for that and filtering for less than \$100,000 contributions, we see that again some values above \$20,000 are skewing the contribution amount count. Finally, adjusting for donations less than \$10,000 we see a semblance of distribution of contributions, with a good majority being less than \$2000.


## Answer 6)
We can do the following task with the following code block

```{r}
candidate_contri <- campaign_data_mayoral|>
                    group_by(candidate) |>
                    summarise(
                    total_contri = sum(contribution_amount, na.rm = TRUE),
                    mean_contri = mean(contribution_amount, na.rm = TRUE),
                    contri_count = n()
                    )

top_total_contri <- candidate_contri |>
                    arrange(-total_contri)|>
                    select(candidate,total_contri)|>
                    head(5)
top_mean_contri <- candidate_contri |>
                   arrange(-mean_contri)|>
                   select(candidate,mean_contri)|>
                   head(5)
top_contri_count <- candidate_contri |>
                    arrange(-contri_count)|>
                    select(candidate,contri_count)|>
                    head(5)

top_total_contri
top_mean_contri
top_contri_count
```

## Answer 7)
We can do this task with just a few revisions
```{r}
non_candidate_contri <- campaign_data_mayoral |>
                        filter(contributors_name != candidate)

non_candidate_contri <- non_candidate_contri|>
                        group_by(candidate) |>
                        summarise(
                        total_contri_popular = sum(contribution_amount, na.rm = TRUE),
                        mean_contri_popular = mean(contribution_amount, na.rm = TRUE),
                        contri_count_popular = n()
                    )

top_total_contri_popular <- non_candidate_contri |>
                            arrange(-total_contri_popular)|>
                            select(candidate,total_contri_popular)|>
                            head(5)
top_mean_contri_popular <- non_candidate_contri |>
                           arrange(-mean_contri_popular)|>
                           select(candidate,mean_contri_popular)|>
                           head(5)
top_contri_count_popular <- non_candidate_contri |>
                            arrange(-contri_count_popular)|>
                            select(candidate,contri_count_popular)|>
                            head(5)
top_total_contri_popular
top_mean_contri_popular
top_contri_count_popular



```

## Answer 8)

We can count the number of people who donated to multiple candidates with the following code:
```{r}

multiple_contri <- campaign_data_mayoral |>
  group_by(contributors_name) |>
  summarise(unique_candidates = n_distinct(candidate)) 

multiple_contri_count <- sum(multiple_contri$unique_candidates > 1)

multiple_contri_count




```

We see that 184 people donated to multiple candidates.